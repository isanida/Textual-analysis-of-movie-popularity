# Textual-analysis-of-movie-popularity

Being able to predict the success of a movie before it is produced would be highly beneficial, specifically for movie producers. In the present project we address this task using solely information available from text related to the film. That is, primarily the script but in comparison also a neutral summary of the content. We motivate a first generative model for the production of this textual data: what if the “topics” Latent Dirichlet Allocation learns, restricted to a given movie genre, corresponded to successful and unsuccessful language models for those movies? It turns out that this first generative model does not suffice. Therefore we refine the approach to directly include the success variable and thus enforce a connection of the learned classes to success. We derive Gibbs sampling for this model and apply it to learn the latent variables. Afterwards we use these learned variables to predict movie scores of unknown movies based on solely their textual data. Predictions turn out not to be highly accurate, which indicates that the model still needs further refinement.

Dataset:
The Dataset we need has to contain scripts and summaries of movies together with certain metadata, namely IMDb scores for measuring success as well as genres a film belongs to. We obtained such a dataset by combining two freely available sources. The first one was generated by Danescu-Niculescu-Mizil and Lee for their 2011 paper “Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs”. This dataset contains
conversations from the scripts of 617 movies. The relevant metadata is also provided in a separate file. The second dataset which we used contains the summaries of 42,306 movies and was generated by Bamman, O’Connor and Smith for their 2013 paper “Learning Latent Personas of Film Characters”. They once more also provided the relevant metadata. IMDb scores and genres in the two datasets coincided precisely, as the genres were in both cases also obtained from information on the
IMDb website. We extracted the titles, conversations, summaries, IMDb scores and genres of movies occurring in both datasets. This resulted in a total number of 550 available movies. We stripped the text of special characters and normalised it to have all lower-case characters. In a further step one could keep upper cases and special characters, as they can potentially carry meaning. However, due to the small size of the dataset we decided to favor a higher repetition rate of single words over a greater variability of the features. Having described our data, we can now proceed to discuss the empirical investigations performed on it.
